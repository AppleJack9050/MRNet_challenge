{"cells":[{"cell_type":"markdown","metadata":{"id":"lJcreEvoLAMR"},"source":["**TO DO:** Make a copy of this notebook in your own Google drive and edit the copy.\n","\n","**TO DO:** Download the data at the following link https://stanfordmlgroup.github.io/competitions/mrnet/ and upload it to your Google Drive. \n","\n","This will download a folder named 'data'. \n","\n","*   The dataset consists of 1,250 knee MRIs with image level labels.\n","*   The training data consists of 1,130 MRIs and the validation data consists of 120 MRIs.\n","*   They are labelled as abnormal, having an acl tear and/or meniscus tear.\n","*   Each MRI exam includes data from the axial, coronal and sagittal plane. \n","*   Axial is a Proton-Density series, coronal is a T1-weighted series and sagittal is T2-weighted series.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gAGkxwk-cRff"},"source":["Go to \"Edit\" on the toolbar, then \"Notebook Settings\" and change the hardware accelerator to GPU.\n"]},{"cell_type":"markdown","metadata":{"id":"U1WXxXUT_6_a"},"source":["#Mount Google Drive to access your data\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22416,"status":"ok","timestamp":1656240218516,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"},"user_tz":-60},"id":"gOOfjmRD_ppM","outputId":"5618e905-d1d8-4a08-84a4-83c11ecd5bc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"1jByfpneRc97"},"source":["The following code uses a python library named 'torchsample'. This is not installed in Google Colab. We can import it by running the commands in the following cell. The exclamation mark communicates to Google Colab to run the commands in the terminal rather than in Python in the current notebook.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27889,"status":"ok","timestamp":1656240246401,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"},"user_tz":-60},"id":"FIbY0gCaRvMU","outputId":"4ad2b8f4-ae44-4c99-a822-a4aa2f0861e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining torchsample from git+https://github.com/ncullen93/torchsample.git#egg=torchsample\n","  Cloning https://github.com/ncullen93/torchsample.git to ./src/torchsample\n","  Running command git clone -q https://github.com/ncullen93/torchsample.git /content/src/torchsample\n","Installing collected packages: torchsample\n","  Running setup.py develop for torchsample\n","Successfully installed torchsample-0.1.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting visdom\n","  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n","\u001b[K     |████████████████████████████████| 676 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from visdom) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom) (2.23.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom) (5.1.1)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom) (23.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom) (1.15.0)\n","Collecting jsonpatch\n","  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n","Collecting torchfile\n","  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n","Collecting websocket-client\n","  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.3 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom) (7.1.2)\n","Collecting jsonpointer>=1.9\n","  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2.10)\n","Building wheels for collected packages: visdom, torchfile\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=8dddd5ff5f8609bafb632878c6df265a6d0373317a3cb75ee0cebe8d2d9661fa\n","  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=9733051d069149967b852a6d1c2c65d6b566ee000f768de04053e70cd63a8899\n","  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n","Successfully built visdom torchfile\n","Installing collected packages: jsonpointer, websocket-client, torchfile, jsonpatch, visdom\n","Successfully installed jsonpatch-1.32 jsonpointer-2.3 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.3.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (3.0.2)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from nibabel) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchsample in ./src/torchsample (0.1.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5.1\n"]}],"source":["!pip install -e git+https://github.com/ncullen93/torchsample.git#egg=torchsample\n","!pip install visdom\n","!pip install nibabel\n","!pip install h5py  \n","!pip install torchsample\n","!pip install tensorboardX"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2274,"status":"ok","timestamp":1656240248669,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"},"user_tz":-60},"id":"XoOPghzXShT1"},"outputs":[],"source":["#import all libraries\n","import torch.optim as optim\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","import numpy as np\n","import os\n","import sys\n","import pickle\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import pandas as pd\n","from torch.autograd import Variable\n","from src.torchsample.torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n","from torchvision import transforms\n","from torch.utils.tensorboard import SummaryWriter\n","import math\n","from sklearn import metrics"]},{"cell_type":"markdown","metadata":{"id":"DiUxtO2XCqI-"},"source":["#Define your model\n","The model is defined in the class 'Net'. The 'init' function initialises the architecture of the model.\n","\n","The line of code; ```self.pretrained_model = None``` should be edited to initialise a pre-trained model, pre-trained on the ImageNet Dataset. This initialises the weights of the model with the weights for a pre-trained model that was trained on the ImageNet dataset. This speeds up training.\n","\n","The line of code ```self.classifer = None``` should be edited to be a fully connected layer that makes the final prediction.\n","\n","After the model is initialised, the forward function is called iteratively throughout the training process. \n","\n","More information con defining models can be found at https://pytorch.org/vision/stable/models.html\n","\n","##Fill in None values"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1656240248669,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"},"user_tz":-60},"id":"VRAEyCaIApjx"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.pretrained_model =  nn.Sequential(*list(models.resnet18(pretrained=True).children())[:-1]  )\n","        self.classifer = nn.Linear(512, 1)\n","\n","    \n","    def forward(self, x):\n","        # input size of x (1, s, 3, 256, 256) where s is the number of slices in one MRI\n","        x = torch.squeeze(x, dim=0) #output size (s, 3, 256, 256)\n","        x = self.pretrained_model(x) #input to pretrained model, output size (s, 1000)\n","        output = torch.max(x, 0, keepdim=True)[0] #output size (1, 512)\n","        output = self.classifer(output.squeeze(2).squeeze(2)) #output size (1)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"wOLCnvQ4HUd2"},"source":["#Create Dataloader\n","The 'init' function initialises the dataloader. This class is responsible for loading the datasets. It takes the 'root_dir', 'task', 'plane', 'train' and 'transform' as input parameters. \n","root_dir - the directory to where the data is stored.\n","\n","task - whether the model is being trained to detect acl tears, meniscus tears or abnormalities. Possible values are 'acl', 'meniscus' or 'abnormal'.\n","\n","plane - whether the model is being trained on axial, coronal or sagittal data. Possible values are 'axial', 'coronal' or 'sagittal'.\n","\n","train - is this the dataloader for the training data or the validation data. Possible values are 'True' to load training data or 'False' to load validation data.\n","\n","transform - a compose function for performing transformations to the images.\n","\n","The init function creates 1) a list of paths to each MRI, 2) a corresponding list of labels that are either ones or zeros and 3) weights.\n","\n","\n","---\n","\n","\n","\n","The __len__ function returns the length of the dataset.\n","\n","\n","---\n","The __getitem__ function is iteratively called throughout the training process. It takes an index as a input parameter. It loads the MRI at the given index from the list of paths defined in the init function. It also returns the label and weight for the MRI at that index.\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1656240248669,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"},"user_tz":-60},"id":"AQzFc45wHOwX"},"outputs":[],"source":["class Dataset(data.Dataset):\n","    def __init__(self, root_dir, task, plane, train=False, transform=None):\n","        super().__init__()\n","        self.task = task\n","        self.plane = plane\n","        self.root_dir = root_dir\n","        self.train=train\n","        if self.train == True:\n","            self.folder_path = self.root_dir + 'train/{0}/'.format(plane)\n","            self.records = pd.read_csv(\n","                self.root_dir + 'train-{0}.csv'.format(task), header=None, names=['id', 'label'])\n","        else:\n","            self.folder_path = self.root_dir + 'valid/{0}/'.format(plane)\n","\n","            self.records = pd.read_csv(\n","                self.root_dir + 'valid-{0}.csv'.format(task), header=None, names=['id', 'label'])\n","\n","        self.records['id'] = self.records['id'].map(\n","            lambda i: '0' * (4 - len(str(i))) + str(i))\n","        self.paths = [self.folder_path + filename +\n","                      '.npy' for filename in self.records['id'].tolist()]\n","        self.labels = self.records['label'].tolist()\n","\n","        self.transform = transform\n","        \n","        pos = np.sum(self.labels)\n","        neg = len(self.labels) - pos\n","        self.weights = [1, neg / pos]\n","        \n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, index):\n","        array = np.load(self.paths[index]) #load MRI \n","        label = self.labels[index] #get label of MRI\n","        label = torch.FloatTensor([label]) #convert type from numpy to torch\n","\n","        if self.transform: #if you are transforming it\n","            array = self.transform(array) #transform the image\n","            array = array.numpy()\n","\n","\n","        array = np.stack((array,)*3, axis=1) #the model expects dimensions of (3, 256, 256), the MRIs are greyscale of size (256, 256). Therefore, we stack the image three times to fit the dimensions for the model.\n","        array = torch.FloatTensor(array)\n","\n","        if label.item() == 1:\n","            weight = np.array([self.weights[1]])\n","            weight = torch.FloatTensor(weight)\n","        else:\n","            weight = np.array([self.weights[0]])\n","            weight = torch.FloatTensor(weight)\n","\n","        return array, label, weight"]},{"cell_type":"markdown","metadata":{"id":"Wr_G0QuVedGz"},"source":["#Train the model\n","##Define variables\n","**TO DO:** Change directory to where you store your data. Use the toolbar to the side of this page to view your file system."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":360,"status":"ok","timestamp":1656240452482,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"},"user_tz":-60},"id":"hhB7KNW84hCk"},"outputs":[],"source":["directory='./gdrive/MyDrive/MRNet-v1.0/' #directory to the data\n","task = 'acl'\n","plane = 'sagittal'\n","lr = 1e-5 #learning rate\n","num_epochs = 20 # number of epochs"]},{"cell_type":"markdown","metadata":{"id":"lZgqHPAEoxv2"},"source":["##Initialise the model, optimiser, scheduler, transformations and data loader."]},{"cell_type":"markdown","metadata":{"id":"mgwDd9LmEOyK"},"source":["##Fill in the 'None' values"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18155,"status":"ok","timestamp":1656240266820,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"},"user_tz":-60},"id":"ZOsUXMCT4Y56","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["6ed42754d2794270bac0369bc7ace867","a34dbaa3e70d47f4bdc3303537b039d1","24f17e2095094d40b89f4a84548696f0","ee392e0ccd7a4873bc28ca25a20e4679","a4d8c7c44380491b94afffbfa2d37f0e","dc058130885a4899892655db5cfb3d42","b3138245654c468ea69ac8d86ffa8852","1344ee98431e45e2b58c45a2518b1c18","01210a8d999c41f7a0e869aa39e73164","2691608d6aa44946bdf36dae76388af4","b4bb3b156c39496e8dc949e4007be440"]},"outputId":"0918a9af-c5ba-4909-f4c0-5ab8e88d4028"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ed42754d2794270bac0369bc7ace867"}},"metadata":{}}],"source":["model = Net() #initialise the model\n","if torch.cuda.is_available(): #if there is a GPU available, put the model on the GPU\n","    model = model.cuda()\n","\n","optimizer = optim.Adam(model.parameters(), lr= lr, weight_decay=0.1) #define the optimiser as Adam\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, patience=4, factor=.3, threshold=1e-4, verbose=True) #define a scheduler that decreases the learning rate if there has been no reduction in validation loss is four epochs\n","\n","#define a compose function that is a series of transformations on the images. \n","augmentor = Compose([ \n","            transforms.Lambda(lambda x: torch.Tensor(x)), #converts from numpy to tensor\n","            RandomRotate(25), #rotate the image by 25 degrees\n","            RandomTranslate([0.11, 0.11]), #blur the edges\n","            RandomFlip(), #flip the image\n","        ])\n","\n","# Writer will output to ./runs/ directory by default\n","writer = SummaryWriter(comment='resNet50_result') \n","\n","#initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n","train_dataset = Dataset(directory, task, plane, train=True, transform=augmentor) #create a Dataset object and pass the augmentor the class\n","valid_dataset = Dataset(directory, task, plane, train=False, transform = None) #create a Dataset object for the validation data, don't transform the validation data\n","# set the size of train, validation, test set\n","train_size = 20\n","test_size = len(train_dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n","# load the data\n","# here we going to explain why we set batch size to 32\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=1, shuffle=True, num_workers=2, drop_last=False)\n","valid_loader = torch.utils.data.DataLoader(\n","    valid_dataset, batch_size=1, shuffle=True, num_workers=2, drop_last=False)\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=1, shuffle=True, num_workers=2, drop_last=False)"]},{"cell_type":"markdown","metadata":{"id":"QiJu89o8phOl"},"source":["##Training Loop"]},{"cell_type":"markdown","metadata":{"id":"qunszOdLDn20"},"source":["##Fill in the 'None' values"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561},"id":"V3K5DBz45L6f","executionInfo":{"status":"error","timestamp":1656240567047,"user_tz":-60,"elapsed":112112,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"}},"outputId":"cc311b52-69ac-41d9-cd43-66defe502391"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch : 0 | train loss : 0.7207 | train auc 0.3684 | val loss 0.7492 | val auc 0.6192 \n","------------------------------\n","epoch : 1 | train loss : 0.6866 | train auc 0.3158 | val loss 0.7671 | val auc 0.5971 \n","------------------------------\n","epoch : 2 | train loss : 0.6035 | train auc 0.8421 | val loss 0.7603 | val auc 0.6105 \n","------------------------------\n","epoch : 3 | train loss : 0.5591 | train auc 0.8947 | val loss 0.7948 | val auc 0.5791 \n","------------------------------\n","epoch : 4 | train loss : 0.5509 | train auc 1.0 | val loss 0.831 | val auc 0.5746 \n","------------------------------\n","Epoch 00007: reducing learning rate of group 0 to 3.0000e-06.\n","epoch : 5 | train loss : 0.4705 | train auc 1.0 | val loss 0.8436 | val auc 0.5469 \n","------------------------------\n","epoch : 6 | train loss : 0.4428 | train auc 1.0 | val loss 0.8611 | val auc 0.539 \n","------------------------------\n","epoch : 7 | train loss : 0.5457 | train auc 0.8421 | val loss 0.8698 | val auc 0.5816 \n","------------------------------\n","epoch : 8 | train loss : 0.5264 | train auc 0.8947 | val loss 0.8862 | val auc 0.5511 \n","------------------------------\n","epoch : 9 | train loss : 0.544 | train auc 0.8421 | val loss 0.8616 | val auc 0.5132 \n","------------------------------\n","Early stopping after 10 epochs\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["early_trigger = 10 #if the validation AUC hasn't increased in ten epochs, stop the training\n","early_stop = 0 #counter for the number of iterations where there has been no increase in validation AUC\n","best_val_auc = 0\n","counter = 0\n","progress = []\n","#for loop for each epoch\n","for epoch in range(num_epochs):\n","      #get learning rate\n","      current_lr = lr\n","      _ = model.train()\n","      y_preds = []\n","      y_trues = []\n","      losses = []\n","      \n","\n","      #loop through each MRI in the training set\n","      for i, (image, label, weight) in enumerate(train_loader):\n","          optimizer.zero_grad()\n","\n","          #load all data onto the GPU\n","          if torch.cuda.is_available():\n","              image = image.cuda()\n","              label = label.cuda()\n","              weight = weight.cuda()\n","\n","          label = label[0]\n","          weight = weight[0]\n","\n","          #pass the MRI through the model\n","          prediction = model.forward(image.float()).squeeze(0)\n","\n","          #calculate the loss\n","          loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n","          loss.backward() #back propagation\n","          optimizer.step()\n","\n","          counter += 1\n","          if (counter % 10 == 0):\n","            progress.append(loss.item())\n","            pass\n","\n","          loss_value = loss.item()\n","          losses.append(loss_value)\n","\n","          probas = torch.sigmoid(prediction) #convert output of model (logits) to a value between zero and one using torch.sigmoid(). This can be interpretted as a probability\n","\n","          y_trues.append(int(label[0]))\n","          y_preds.append(probas[0].item())\n","\n","          try:\n","              auc = metrics.roc_auc_score(y_trues, y_preds)\n","          except:\n","              auc = 0.5\n","\n","          train_loss = np.round(np.mean(losses), 4)\n","          train_auc = np.round(auc, 4)\n","          # log each auc\n","          writer.add_scalar('Train/Loss', train_loss,\n","                    epoch * len(train_loader) + i)\n","          writer.add_scalar('Train/AUC', train_auc, epoch * len(train_loader) + i)\n","\n","      # log each epoch\n","      writer.add_scalar('Train/Loss_epoch', sum(losses), epoch + i)\n","      writer.add_scalar('Train/AUC_epoch', auc, epoch + i)\n","\n","\n","      #evaluate the model on the validation data after each epoch\n","      _ = model.eval()\n","      y_trues = []\n","      y_preds = []\n","      losses = []\n","      for i, (image, label, weight) in enumerate(valid_loader):\n","\n","        if torch.cuda.is_available():\n","            image = image.cuda()\n","            label = label.cuda()\n","            weight = weight.cuda()\n","\n","        label = label[0]\n","        weight = weight[0]\n","\n","        prediction = model.forward(image.float()).squeeze(0)\n","\n","        loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n","\n","        loss_value = loss.item()\n","        losses.append(loss_value)\n","\n","        probas = torch.sigmoid(prediction)\n","\n","        y_trues.append(int(label[0]))\n","        y_preds.append(probas[0].item())\n","\n","        try:\n","            auc = metrics.roc_auc_score(y_trues, y_preds)\n","        except:\n","            auc = 0.5\n","\n","        val_loss = np.round(np.mean(losses), 4)\n","        val_auc = np.round(auc, 4)\n","\n","        # log each auc\n","        writer.add_scalar('Val/Loss', val_loss, epoch * len(valid_loader) + i)\n","        writer.add_scalar('Val/AUC', val_auc, epoch * len(valid_loader) + i)\n","        \n","      # log each epoch\n","      writer.add_scalar('Val/Loss_epoch', sum(losses), epoch + i)\n","      writer.add_scalar('Val/AUC_epoch', auc, epoch + i)\n","\n","\n","      if val_auc > best_val_auc:\n","        best_val_auc = val_auc\n","        early_stop=0\n","      else:\n","        early_stop+= 1\n","\n","      if early_stop == early_trigger:\n","        print('Early stopping after {} epochs'.format(epoch))\n","        sys.exit()\n","      scheduler.step(val_loss)\n","\n","      print(\"epoch : {0} | train loss : {1} | train auc {2} | val loss {3} | val auc {4} \".format(\n","          epoch, train_loss, train_auc, val_loss, val_auc))\n","\n","      \n","      print('-' * 30)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2X1T8R94fWtq","executionInfo":{"status":"ok","timestamp":1656240348520,"user_tz":-60,"elapsed":17,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"}}},"outputs":[],"source":["import pandas\n","\n","def plot_progress():\n","    df = pandas.DataFrame(progress, columns=['loss'])\n","    df.plot(ylim=(0, 1.5), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 0.75, 1, 1.25))\n","    pass"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"id":"YMwYFTTW4UiQ","executionInfo":{"status":"ok","timestamp":1656240348520,"user_tz":-60,"elapsed":15,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"}},"outputId":"97eefb99-e0be-4fc8-ee1d-ce90233eb98e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1152x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plot_progress()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"y-vq6WtM38NH","executionInfo":{"status":"ok","timestamp":1656240349511,"user_tz":-60,"elapsed":1004,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"}},"outputId":"b6f89685-fdb9-4ace-9f2f-37761683da3d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7f298e289450>"]},"metadata":{},"execution_count":11},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from sklearn.metrics import RocCurveDisplay\n","RocCurveDisplay.from_predictions(y_trues, y_preds)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"id":"pyBKIuTTJJju","executionInfo":{"status":"error","timestamp":1656241774023,"user_tz":-60,"elapsed":678554,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"}},"outputId":"c2abab6d-dfa3-4a56-a157-39dc6d11033a"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-126c3bda57e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_trues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}],"source":["y_preds = []\n","y_trues = []\n","\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in test_loader:\n","        image, label, _ = data\n","\n","        if torch.cuda.is_available():\n","          image = image.cuda()\n","          label = label.cuda()\n","\n","        prediction = model.forward(image.float()).squeeze(0)\n","\n","        probas = torch.sigmoid(prediction)\n","\n","        y_trues.append(int(label[0]))\n","        y_preds.append(probas[0].item())\n","\n","    auc = metrics.accuracy_score(y_trues, y_preds)\n","\n","\n","print(f'AUC: ', auc)"]},{"cell_type":"code","source":["y_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wPadZqstT_A","executionInfo":{"status":"ok","timestamp":1656241891619,"user_tz":-60,"elapsed":384,"user":{"displayName":"Sicheng Zhao","userId":"16759370774888104625"}},"outputId":"ff862793-9d75-4e65-9bb2-5dfdee7f4759"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.26331794261932373,\n"," 0.25941556692123413,\n"," 0.21371717751026154,\n"," 0.3099943697452545,\n"," 0.2716691493988037,\n"," 0.3409633934497833,\n"," 0.28668007254600525,\n"," 0.33195143938064575,\n"," 0.12953218817710876,\n"," 0.18861719965934753,\n"," 0.24078482389450073,\n"," 0.3276415169239044,\n"," 0.31805703043937683,\n"," 0.268174409866333,\n"," 0.17400147020816803,\n"," 0.35850009322166443,\n"," 0.23837530612945557,\n"," 0.22408360242843628,\n"," 0.24774610996246338,\n"," 0.2648366391658783,\n"," 0.27038276195526123,\n"," 0.21093235909938812,\n"," 0.17963626980781555,\n"," 0.298137366771698,\n"," 0.37289196252822876,\n"," 0.22113661468029022,\n"," 0.23982948064804077,\n"," 0.31004706025123596,\n"," 0.14304955303668976,\n"," 0.23640821874141693,\n"," 0.36943140625953674,\n"," 0.2466859221458435,\n"," 0.1766291707754135,\n"," 0.1945122331380844,\n"," 0.23233990371227264,\n"," 0.28200122714042664,\n"," 0.30755582451820374,\n"," 0.24943411350250244,\n"," 0.24709132313728333,\n"," 0.243154376745224,\n"," 0.38540583848953247,\n"," 0.34793519973754883,\n"," 0.20296038687229156,\n"," 0.2864435911178589,\n"," 0.2204871028661728,\n"," 0.2895570695400238,\n"," 0.2072877734899521,\n"," 0.24039354920387268,\n"," 0.3710521161556244,\n"," 0.22533608973026276,\n"," 0.25973835587501526,\n"," 0.3033481538295746,\n"," 0.3152342140674591,\n"," 0.2306506186723709,\n"," 0.36347830295562744,\n"," 0.2834031283855438,\n"," 0.2539178729057312,\n"," 0.30804917216300964,\n"," 0.2648012638092041,\n"," 0.3343307375907898,\n"," 0.24972891807556152,\n"," 0.20931172370910645,\n"," 0.2323487102985382,\n"," 0.2908397614955902,\n"," 0.2076328843832016,\n"," 0.16079968214035034,\n"," 0.20928941667079926,\n"," 0.2734614312648773,\n"," 0.25716546177864075,\n"," 0.2722194790840149,\n"," 0.21023258566856384,\n"," 0.21418751776218414,\n"," 0.34198886156082153,\n"," 0.2619394063949585,\n"," 0.19175349175930023,\n"," 0.2878042161464691,\n"," 0.22549188137054443,\n"," 0.37320125102996826,\n"," 0.2512153387069702,\n"," 0.2052462249994278,\n"," 0.32186874747276306,\n"," 0.32026830315589905,\n"," 0.18909722566604614,\n"," 0.24583116173744202,\n"," 0.307677298784256,\n"," 0.24280764162540436,\n"," 0.23763792216777802,\n"," 0.19754347205162048,\n"," 0.2811710834503174,\n"," 0.36807993054389954,\n"," 0.27692508697509766,\n"," 0.24079184234142303,\n"," 0.22513887286186218,\n"," 0.19677233695983887,\n"," 0.3632296919822693,\n"," 0.16574831306934357,\n"," 0.3743976950645447,\n"," 0.1991252452135086,\n"," 0.25728774070739746,\n"," 0.257426917552948,\n"," 0.3107457756996155,\n"," 0.2263360470533371,\n"," 0.2733096778392792,\n"," 0.21715424954891205,\n"," 0.26281625032424927,\n"," 0.359712153673172,\n"," 0.2958899736404419,\n"," 0.17966264486312866,\n"," 0.28996801376342773,\n"," 0.25330373644828796,\n"," 0.18115483224391937,\n"," 0.31334856152534485,\n"," 0.376583069562912,\n"," 0.3339938819408417,\n"," 0.30802521109580994,\n"," 0.2821684181690216,\n"," 0.27758681774139404,\n"," 0.18836283683776855,\n"," 0.15935270488262177,\n"," 0.22920873761177063,\n"," 0.3299177289009094,\n"," 0.23465777933597565,\n"," 0.2363094687461853,\n"," 0.26443174481391907,\n"," 0.1902264803647995,\n"," 0.1989777684211731,\n"," 0.16969020664691925,\n"," 0.33759403228759766,\n"," 0.2926254868507385,\n"," 0.1883620172739029,\n"," 0.12720812857151031,\n"," 0.3209521770477295,\n"," 0.19000385701656342,\n"," 0.3093756139278412,\n"," 0.23033778369426727,\n"," 0.2867547571659088,\n"," 0.30264541506767273,\n"," 0.24142836034297943,\n"," 0.2505437135696411,\n"," 0.3789064288139343,\n"," 0.26296013593673706,\n"," 0.29579097032546997,\n"," 0.22952203452587128,\n"," 0.22383134067058563,\n"," 0.20899780094623566,\n"," 0.20451273024082184,\n"," 0.18245474994182587,\n"," 0.1479843109846115,\n"," 0.2521504759788513,\n"," 0.285776823759079,\n"," 0.2961415946483612,\n"," 0.25607627630233765,\n"," 0.13448132574558258,\n"," 0.2616141736507416,\n"," 0.2831462621688843,\n"," 0.378084659576416,\n"," 0.4022592306137085,\n"," 0.27201539278030396,\n"," 0.24645695090293884,\n"," 0.3712802827358246,\n"," 0.2519896626472473,\n"," 0.2511429190635681,\n"," 0.19409185647964478,\n"," 0.2950232923030853,\n"," 0.2502560019493103,\n"," 0.37999260425567627,\n"," 0.3073229491710663,\n"," 0.181741401553154,\n"," 0.1802404820919037,\n"," 0.329776406288147,\n"," 0.2472512573003769,\n"," 0.20165640115737915,\n"," 0.1790754348039627,\n"," 0.30713626742362976,\n"," 0.25408291816711426,\n"," 0.2525579333305359,\n"," 0.23469026386737823,\n"," 0.29449331760406494,\n"," 0.2566935122013092,\n"," 0.3539186120033264,\n"," 0.17970825731754303,\n"," 0.22133946418762207,\n"," 0.19280177354812622,\n"," 0.28858986496925354,\n"," 0.1897268146276474,\n"," 0.2283671498298645,\n"," 0.13797572255134583,\n"," 0.2167263925075531,\n"," 0.34915870428085327,\n"," 0.3150796890258789,\n"," 0.1695391684770584,\n"," 0.2357165813446045,\n"," 0.2416074275970459,\n"," 0.3545147478580475,\n"," 0.21095918118953705,\n"," 0.3124920427799225,\n"," 0.23405137658119202,\n"," 0.3316729962825775,\n"," 0.2551111876964569,\n"," 0.26594337821006775,\n"," 0.2587188482284546,\n"," 0.20721764862537384,\n"," 0.22732983529567719,\n"," 0.21947281062602997,\n"," 0.26983726024627686,\n"," 0.278690367937088,\n"," 0.20397359132766724,\n"," 0.2720249593257904,\n"," 0.30202576518058777,\n"," 0.24500498175621033,\n"," 0.23685595393180847,\n"," 0.4875011742115021,\n"," 0.3486839830875397,\n"," 0.13120624423027039,\n"," 0.25232240557670593,\n"," 0.21108782291412354,\n"," 0.16185662150382996,\n"," 0.2583439350128174,\n"," 0.198616623878479,\n"," 0.35598447918891907,\n"," 0.21222570538520813,\n"," 0.42206066846847534,\n"," 0.3155336380004883,\n"," 0.2587246596813202,\n"," 0.2970871329307556,\n"," 0.18070830404758453,\n"," 0.26746752858161926,\n"," 0.22624050080776215,\n"," 0.24444541335105896,\n"," 0.23862065374851227,\n"," 0.15428367257118225,\n"," 0.22792261838912964,\n"," 0.14641594886779785,\n"," 0.34940680861473083,\n"," 0.09159179776906967,\n"," 0.2982141673564911,\n"," 0.2550364136695862,\n"," 0.24400952458381653,\n"," 0.14838962256908417,\n"," 0.21493639051914215,\n"," 0.2934137284755707,\n"," 0.2652550935745239,\n"," 0.2749583423137665,\n"," 0.20921535789966583,\n"," 0.2243267148733139,\n"," 0.25730299949645996,\n"," 0.1881546974182129,\n"," 0.3119972050189972,\n"," 0.23174123466014862,\n"," 0.3378080725669861,\n"," 0.24521787464618683,\n"," 0.3661814033985138,\n"," 0.21134811639785767,\n"," 0.25346463918685913,\n"," 0.3555022180080414,\n"," 0.3159431219100952,\n"," 0.22734665870666504,\n"," 0.2845134139060974,\n"," 0.32131439447402954,\n"," 0.22042784094810486,\n"," 0.3308967649936676,\n"," 0.2762849032878876,\n"," 0.1351475715637207,\n"," 0.3219907879829407,\n"," 0.3096989691257477,\n"," 0.21993520855903625,\n"," 0.2532925307750702,\n"," 0.27395984530448914,\n"," 0.2964977025985718,\n"," 0.18585924804210663,\n"," 0.3317679762840271,\n"," 0.2406076341867447,\n"," 0.29334548115730286,\n"," 0.2590142786502838,\n"," 0.34567439556121826,\n"," 0.29698625206947327,\n"," 0.4951041042804718,\n"," 0.26252713799476624,\n"," 0.20657843351364136,\n"," 0.17431700229644775,\n"," 0.22032274305820465,\n"," 0.24912190437316895,\n"," 0.23974506556987762,\n"," 0.26661843061447144,\n"," 0.22189760208129883,\n"," 0.2774195373058319,\n"," 0.22039538621902466,\n"," 0.2682715356349945,\n"," 0.2444523721933365,\n"," 0.3259163796901703,\n"," 0.24602170288562775,\n"," 0.2599457800388336,\n"," 0.22445139288902283,\n"," 0.19794896245002747,\n"," 0.2293470799922943,\n"," 0.3219947814941406,\n"," 0.30981874465942383,\n"," 0.25788208842277527,\n"," 0.16532540321350098,\n"," 0.2779273986816406,\n"," 0.1974640190601349,\n"," 0.2957070767879486,\n"," 0.16763430833816528,\n"," 0.3002164661884308,\n"," 0.28693532943725586,\n"," 0.2231764942407608,\n"," 0.19944961369037628,\n"," 0.227463498711586,\n"," 0.2391117364168167,\n"," 0.22213125228881836,\n"," 0.26883336901664734,\n"," 0.18391530215740204,\n"," 0.2660154700279236,\n"," 0.17691688239574432,\n"," 0.2449551820755005,\n"," 0.26178407669067383,\n"," 0.3665913939476013,\n"," 0.2654244899749756,\n"," 0.2279476374387741,\n"," 0.21188078820705414,\n"," 0.24782322347164154,\n"," 0.2889559864997864,\n"," 0.32650497555732727,\n"," 0.21128740906715393,\n"," 0.38463008403778076,\n"," 0.21504536271095276,\n"," 0.24197857081890106,\n"," 0.38745570182800293,\n"," 0.3831019401550293,\n"," 0.2995947599411011,\n"," 0.2510419487953186,\n"," 0.329662024974823,\n"," 0.2739386260509491,\n"," 0.2927461862564087,\n"," 0.18593467772006989,\n"," 0.173395037651062,\n"," 0.27821096777915955,\n"," 0.27374669909477234,\n"," 0.3473474383354187,\n"," 0.2862372100353241,\n"," 0.24579022824764252,\n"," 0.27143651247024536,\n"," 0.25436335802078247,\n"," 0.38912034034729004,\n"," 0.20663921535015106,\n"," 0.2219352126121521,\n"," 0.27821436524391174,\n"," 0.36826783418655396,\n"," 0.32482221722602844,\n"," 0.39870432019233704,\n"," 0.2855290472507477,\n"," 0.2586401402950287,\n"," 0.25756943225860596,\n"," 0.24077564477920532,\n"," 0.27155759930610657,\n"," 0.18557530641555786,\n"," 0.25549864768981934,\n"," 0.26843908429145813,\n"," 0.31091946363449097,\n"," 0.33456823229789734,\n"," 0.2989598214626312,\n"," 0.28686511516571045,\n"," 0.32331523299217224,\n"," 0.37576690316200256,\n"," 0.28595277667045593,\n"," 0.4057554602622986,\n"," 0.24687127768993378,\n"," 0.2062181532382965,\n"," 0.3606101870536804,\n"," 0.22330579161643982,\n"," 0.21334613859653473,\n"," 0.3356800377368927,\n"," 0.2988075017929077,\n"," 0.17052245140075684,\n"," 0.19454661011695862,\n"," 0.3003624677658081,\n"," 0.21800392866134644,\n"," 0.23065954446792603,\n"," 0.19205732643604279,\n"," 0.27321186661720276,\n"," 0.16600503027439117,\n"," 0.27333253622055054,\n"," 0.23761580884456635,\n"," 0.27306047081947327,\n"," 0.3502384126186371,\n"," 0.1782020926475525,\n"," 0.393761545419693,\n"," 0.23211823403835297,\n"," 0.37085413932800293,\n"," 0.2261228859424591,\n"," 0.3684587776660919,\n"," 0.09847676753997803,\n"," 0.3988857865333557,\n"," 0.2794702649116516,\n"," 0.37119773030281067,\n"," 0.33702340722084045,\n"," 0.24723388254642487,\n"," 0.40109118819236755,\n"," 0.19110766053199768,\n"," 0.28734683990478516,\n"," 0.24499940872192383,\n"," 0.25044578313827515,\n"," 0.2692444920539856,\n"," 0.3340776264667511,\n"," 0.3030260503292084,\n"," 0.37151917815208435,\n"," 0.22147227823734283,\n"," 0.19661250710487366,\n"," 0.35422319173812866,\n"," 0.2188640981912613,\n"," 0.29404008388519287,\n"," 0.33888834714889526,\n"," 0.2691749036312103,\n"," 0.22347880899906158,\n"," 0.3140157163143158,\n"," 0.24124650657176971,\n"," 0.2214130312204361,\n"," 0.2742899954319,\n"," 0.34123292565345764,\n"," 0.2254873663187027,\n"," 0.3321516811847687,\n"," 0.16781234741210938,\n"," 0.340713769197464,\n"," 0.27142804861068726,\n"," 0.2413497269153595,\n"," 0.3854953944683075,\n"," 0.25640738010406494,\n"," 0.32371336221694946,\n"," 0.349407821893692,\n"," 0.3307855725288391,\n"," 0.32658666372299194,\n"," 0.31043192744255066,\n"," 0.2943805754184723,\n"," 0.17301763594150543,\n"," 0.3116627633571625,\n"," 0.37684088945388794,\n"," 0.2588125467300415,\n"," 0.21661235392093658,\n"," 0.2686013877391815,\n"," 0.1730833351612091,\n"," 0.25015875697135925,\n"," 0.1479695439338684,\n"," 0.24055467545986176,\n"," 0.23706790804862976,\n"," 0.2394692599773407,\n"," 0.1632009595632553,\n"," 0.14106422662734985,\n"," 0.29210084676742554,\n"," 0.1843884289264679,\n"," 0.24291899800300598,\n"," 0.1864025890827179,\n"," 0.20384733378887177,\n"," 0.1860341727733612,\n"," 0.270118772983551,\n"," 0.20886832475662231,\n"," 0.2882698178291321,\n"," 0.35164621472358704,\n"," 0.24284785985946655,\n"," 0.31205376982688904,\n"," 0.3297507166862488,\n"," 0.160403773188591,\n"," 0.27563005685806274,\n"," 0.27896949648857117,\n"," 0.32461628317832947,\n"," 0.2750984728336334,\n"," 0.266171395778656,\n"," 0.23808681964874268,\n"," 0.3332100808620453,\n"," 0.24357324838638306,\n"," 0.2851918041706085,\n"," 0.27038607001304626,\n"," 0.20390163362026215,\n"," 0.2196144014596939,\n"," 0.1732679158449173,\n"," 0.29873940348625183,\n"," 0.2684521973133087,\n"," 0.2542496919631958,\n"," 0.27649182081222534,\n"," 0.20315732061862946,\n"," 0.36619502305984497,\n"," 0.2769186496734619,\n"," 0.21464380621910095,\n"," 0.25381043553352356,\n"," 0.15285871922969818,\n"," 0.3064568042755127,\n"," 0.20707571506500244,\n"," 0.14643564820289612,\n"," 0.15706032514572144,\n"," 0.2093188762664795,\n"," 0.18964225053787231,\n"," 0.3814130425453186,\n"," 0.3277335464954376,\n"," 0.24588727951049805,\n"," 0.16991017758846283,\n"," 0.2958264946937561,\n"," 0.2532440721988678,\n"," 0.43897515535354614,\n"," 0.3296375572681427,\n"," 0.3065422475337982,\n"," 0.17128679156303406,\n"," 0.269548624753952,\n"," 0.24726611375808716,\n"," 0.2781023681163788,\n"," 0.3388036787509918,\n"," 0.21585164964199066,\n"," 0.2635691165924072,\n"," 0.15484951436519623,\n"," 0.24601221084594727,\n"," 0.31319868564605713,\n"," 0.297350138425827,\n"," 0.24287772178649902,\n"," 0.2323986291885376,\n"," 0.30184227228164673,\n"," 0.3141562342643738,\n"," 0.365992933511734,\n"," 0.3835293650627136,\n"," 0.3660936653614044,\n"," 0.22878018021583557,\n"," 0.24496817588806152,\n"," 0.26658156514167786,\n"," 0.21508289873600006,\n"," 0.2058112919330597,\n"," 0.34079447388648987,\n"," 0.35451003909111023,\n"," 0.2632841467857361,\n"," 0.22883690893650055,\n"," 0.25884875655174255,\n"," 0.26390349864959717,\n"," 0.2220107764005661,\n"," 0.28782203793525696,\n"," 0.2632843255996704,\n"," 0.21510691940784454,\n"," 0.1643785536289215,\n"," 0.23207810521125793,\n"," 0.35768020153045654,\n"," 0.3093424439430237,\n"," 0.30979251861572266,\n"," 0.18680086731910706,\n"," 0.23283781111240387,\n"," 0.2634510397911072,\n"," 0.2506173849105835,\n"," 0.19013333320617676,\n"," 0.278385728597641,\n"," 0.331862211227417,\n"," 0.39562809467315674,\n"," 0.26102718710899353,\n"," 0.19102418422698975,\n"," 0.1927640736103058,\n"," 0.26669761538505554,\n"," 0.24833166599273682,\n"," 0.3672087788581848,\n"," 0.23760919272899628,\n"," 0.41876664757728577,\n"," 0.26666903495788574,\n"," 0.1784304827451706,\n"," 0.3001883625984192,\n"," 0.2897754907608032,\n"," 0.30968576669692993,\n"," 0.2981680631637573,\n"," 0.27021071314811707,\n"," 0.24683092534542084,\n"," 0.2170240432024002,\n"," 0.203878253698349,\n"," 0.28034496307373047,\n"," 0.22921893000602722,\n"," 0.1905987411737442,\n"," 0.22050021588802338,\n"," 0.3059370517730713,\n"," 0.2590695321559906,\n"," 0.21666808426380157,\n"," 0.2877689301967621,\n"," 0.2907911539077759,\n"," 0.23150160908699036,\n"," 0.25338950753211975,\n"," 0.305941641330719,\n"," 0.3523048460483551,\n"," 0.3077130615711212,\n"," 0.29176345467567444,\n"," 0.2817014753818512,\n"," 0.21722708642482758,\n"," 0.24796071648597717,\n"," 0.3233047127723694,\n"," 0.209250807762146,\n"," 0.28297391533851624,\n"," 0.24788884818553925,\n"," 0.2654730975627899,\n"," 0.25692248344421387,\n"," 0.20506608486175537,\n"," 0.40858396887779236,\n"," 0.43239009380340576,\n"," 0.2307365983724594,\n"," 0.26122719049453735,\n"," 0.35171669721603394,\n"," 0.3336901366710663,\n"," 0.2771010398864746,\n"," 0.2192430943250656,\n"," 0.16620561480522156,\n"," 0.27008476853370667,\n"," 0.31135794520378113,\n"," 0.2912693917751312,\n"," 0.25074946880340576,\n"," 0.18594911694526672,\n"," 0.3353768587112427,\n"," 0.2745579183101654,\n"," 0.24520929157733917,\n"," 0.35985082387924194,\n"," 0.1871221363544464,\n"," 0.16712884604930878,\n"," 0.20100180804729462,\n"," 0.3195905089378357,\n"," 0.2740257978439331,\n"," 0.31064531207084656,\n"," 0.2673262655735016,\n"," 0.3599758446216583,\n"," 0.1877846121788025,\n"," 0.2043950855731964,\n"," 0.2100973278284073,\n"," 0.27340710163116455,\n"," 0.29200682044029236,\n"," 0.2448517382144928,\n"," 0.19090569019317627,\n"," 0.29317599534988403,\n"," 0.14924554526805878,\n"," 0.17670997977256775,\n"," 0.22799614071846008,\n"," 0.25437554717063904,\n"," 0.4072025418281555,\n"," 0.2839527428150177,\n"," 0.20637567341327667,\n"," 0.2807084023952484,\n"," 0.16985781490802765,\n"," 0.19404834508895874,\n"," 0.24632656574249268,\n"," 0.20922711491584778,\n"," 0.14514556527137756,\n"," 0.12179792672395706,\n"," 0.15842700004577637,\n"," 0.12967485189437866,\n"," 0.2238464057445526,\n"," 0.3167191743850708,\n"," 0.23943215608596802,\n"," 0.232321634888649,\n"," 0.2571122944355011,\n"," 0.24400492012500763,\n"," 0.1664198786020279,\n"," 0.4039757549762726,\n"," 0.23029682040214539,\n"," 0.20720553398132324,\n"," 0.2460041046142578,\n"," 0.2421482503414154,\n"," 0.23030583560466766,\n"," 0.1921955943107605,\n"," 0.18998758494853973,\n"," 0.2485514134168625,\n"," 0.2927911877632141,\n"," 0.26089730858802795,\n"," 0.2632591724395752,\n"," 0.2596055269241333,\n"," 0.23032692074775696,\n"," 0.22966158390045166,\n"," 0.24363385140895844,\n"," 0.3637246787548065,\n"," 0.3268809914588928,\n"," 0.21360738575458527,\n"," 0.1676008254289627,\n"," 0.28090864419937134,\n"," 0.2428377866744995,\n"," 0.20738521218299866,\n"," 0.2537976801395416,\n"," 0.2942363917827606,\n"," 0.24534550309181213,\n"," 0.14576297998428345,\n"," 0.1935708373785019,\n"," 0.300098180770874,\n"," 0.291581392288208,\n"," 0.1729641556739807,\n"," 0.20673523843288422,\n"," 0.2455586940050125,\n"," 0.1909504234790802,\n"," 0.28953999280929565,\n"," 0.2985159158706665,\n"," 0.2408951222896576,\n"," 0.2702119052410126,\n"," 0.23825952410697937,\n"," 0.3108915388584137,\n"," 0.2783373296260834,\n"," 0.3120516836643219,\n"," 0.22452610731124878,\n"," 0.42159631848335266,\n"," 0.2722173035144806,\n"," 0.23862870037555695,\n"," 0.3296012878417969,\n"," 0.18893152475357056,\n"," 0.39609605073928833,\n"," 0.2706722319126129,\n"," 0.2024887055158615,\n"," 0.2211005985736847,\n"," 0.14765237271785736,\n"," 0.43507176637649536,\n"," 0.27714940905570984,\n"," 0.22849728167057037,\n"," 0.3621049225330353,\n"," 0.3500133156776428,\n"," 0.15503916144371033,\n"," 0.19074572622776031,\n"," 0.2573958933353424,\n"," 0.23856505751609802,\n"," 0.18846018612384796,\n"," 0.20501939952373505,\n"," 0.21201729774475098,\n"," 0.18949705362319946,\n"," 0.23477041721343994,\n"," 0.2615605294704437,\n"," 0.3872974216938019,\n"," 0.2433055192232132,\n"," 0.18513569235801697,\n"," 0.4155939221382141,\n"," 0.16578751802444458,\n"," 0.27368324995040894,\n"," 0.27506741881370544,\n"," 0.3002506196498871,\n"," 0.29649782180786133,\n"," 0.19119958579540253,\n"," 0.26098597049713135,\n"," 0.3030097186565399,\n"," 0.30866214632987976,\n"," 0.2714763879776001,\n"," 0.2871747612953186,\n"," 0.21911689639091492,\n"," 0.22350534796714783,\n"," 0.4364505708217621,\n"," 0.34231266379356384,\n"," 0.2893805205821991,\n"," 0.2331237643957138,\n"," 0.19393010437488556,\n"," 0.22655469179153442,\n"," 0.2627738416194916,\n"," 0.268987238407135,\n"," 0.1918811798095703,\n"," 0.32957178354263306,\n"," 0.2322877049446106,\n"," 0.27959075570106506,\n"," 0.2540122866630554,\n"," 0.21487723290920258,\n"," 0.30991700291633606,\n"," 0.3441438376903534,\n"," 0.16959436237812042,\n"," 0.2050665318965912,\n"," 0.2541332542896271,\n"," 0.2510557472705841,\n"," 0.22132568061351776,\n"," 0.22324468195438385,\n"," 0.4018733501434326,\n"," 0.24281813204288483,\n"," 0.22527295351028442,\n"," 0.23251821100711823,\n"," 0.20801134407520294,\n"," 0.15034633874893188,\n"," 0.13878676295280457,\n"," 0.3226087689399719,\n"," 0.33617904782295227,\n"," 0.3146422505378723,\n"," 0.28007781505584717,\n"," 0.16086037456989288,\n"," 0.25160107016563416,\n"," 0.4044194519519806,\n"," 0.247187539935112,\n"," 0.23833845555782318,\n"," 0.20495390892028809,\n"," 0.24152907729148865,\n"," 0.3437868058681488,\n"," 0.12675504386425018,\n"," 0.20869559049606323,\n"," 0.28304046392440796,\n"," 0.2984686493873596,\n"," 0.2675759792327881,\n"," 0.24869757890701294,\n"," 0.3782193064689636,\n"," 0.24830614030361176,\n"," 0.2695353031158447,\n"," 0.15158545970916748,\n"," 0.2858979105949402,\n"," 0.3240906298160553,\n"," 0.37844863533973694,\n"," 0.3196524679660797,\n"," 0.35213422775268555,\n"," 0.3164224922657013,\n"," 0.2459704577922821,\n"," 0.2861982583999634,\n"," 0.21026265621185303,\n"," 0.25533899664878845,\n"," 0.21991148591041565,\n"," 0.26174190640449524,\n"," 0.21467913687229156,\n"," 0.25615501403808594,\n"," 0.3044758141040802,\n"," 0.17328998446464539,\n"," 0.3471836447715759,\n"," 0.17167237401008606,\n"," 0.3429591655731201,\n"," 0.22399552166461945,\n"," 0.35952818393707275,\n"," 0.25986114144325256,\n"," 0.2517164349555969,\n"," 0.29293274879455566,\n"," 0.2005142867565155,\n"," 0.27462539076805115,\n"," 0.1474323272705078,\n"," 0.3363310992717743,\n"," 0.37256526947021484,\n"," 0.2600475251674652,\n"," 0.1886495053768158,\n"," 0.26649776101112366,\n"," 0.18868136405944824,\n"," 0.3187839984893799,\n"," 0.17683207988739014,\n"," 0.2075846940279007,\n"," 0.22664768993854523,\n"," 0.22186022996902466,\n"," 0.3883287012577057,\n"," 0.2253841757774353,\n"," 0.2403285950422287,\n"," 0.4143206775188446,\n"," 0.3424309492111206,\n"," 0.20288436114788055,\n"," 0.2729546129703522,\n"," 0.3059793710708618,\n"," 0.3556860387325287,\n"," 0.2744033932685852,\n"," 0.3143075704574585,\n"," 0.3650118410587311,\n"," 0.36160343885421753,\n"," 0.10946182906627655,\n"," 0.23350870609283447,\n"," 0.2124248445034027,\n"," 0.29286062717437744,\n"," 0.34125614166259766,\n"," 0.2886098325252533,\n"," 0.2637055814266205,\n"," 0.15098635852336884,\n"," 0.31089863181114197,\n"," 0.25185132026672363,\n"," 0.3066328763961792,\n"," 0.4094626009464264,\n"," 0.2072814404964447,\n"," 0.24811577796936035,\n"," 0.2876456081867218,\n"," 0.2830081284046173,\n"," 0.24261189997196198,\n"," 0.2867146134376526,\n"," 0.2366255670785904,\n"," 0.28613904118537903,\n"," 0.1655951738357544,\n"," 0.267659455537796,\n"," 0.40989580750465393,\n"," 0.20381440222263336,\n"," 0.14241382479667664,\n"," 0.2814484238624573,\n"," 0.2977839708328247,\n"," 0.24999487400054932,\n"," 0.318053662776947,\n"," 0.2956880033016205,\n"," 0.2217673659324646,\n"," 0.2099820077419281,\n"," 0.28377601504325867,\n"," 0.35521116852760315,\n"," 0.3796957731246948,\n"," 0.3019035756587982,\n"," 0.2758565843105316,\n"," 0.2619703412055969,\n"," 0.33828577399253845,\n"," 0.3502216935157776,\n"," 0.14173591136932373,\n"," 0.2949271500110626,\n"," 0.4139542877674103,\n"," 0.20266017317771912,\n"," 0.3611835539340973,\n"," 0.29322972893714905,\n"," 0.32663068175315857,\n"," 0.2420550137758255,\n"," 0.24639907479286194,\n"," 0.2574838399887085,\n"," 0.19376537203788757,\n"," 0.193959578871727,\n"," 0.24061602354049683,\n"," 0.23939235508441925,\n"," 0.16296903789043427,\n"," 0.33047860860824585,\n"," 0.3625011742115021,\n"," 0.248291477560997,\n"," 0.2597614526748657,\n"," 0.2399333119392395,\n"," 0.3140295445919037,\n"," 0.21141843497753143,\n"," 0.24782395362854004,\n"," 0.27540621161460876,\n"," 0.19725866615772247,\n"," 0.2639572322368622,\n"," 0.18389326333999634,\n"," 0.3508242964744568,\n"," 0.2216707020998001,\n"," 0.2640624940395355,\n"," 0.34952735900878906,\n"," 0.3454134166240692,\n"," 0.3083251714706421,\n"," 0.1405104398727417,\n"," 0.35532984137535095,\n"," 0.17270112037658691,\n"," 0.16768395900726318,\n"," 0.501668393611908,\n"," 0.21219995617866516,\n"," 0.300576388835907,\n"," 0.23799462616443634,\n"," 0.35400256514549255,\n"," 0.26064956188201904,\n"," 0.26098254323005676,\n"," 0.24967527389526367,\n"," 0.31635576486587524,\n"," 0.21037819981575012,\n"," 0.2345808446407318,\n"," 0.3232092261314392,\n"," 0.33354589343070984,\n"," 0.35590511560440063,\n"," 0.15527263283729553,\n"," 0.17664282023906708,\n"," 0.10795612633228302,\n"," 0.27736401557922363,\n"," 0.23482178151607513,\n"," 0.20124532282352448,\n"," 0.3426232933998108,\n"," 0.19477157294750214,\n"," 0.35793501138687134,\n"," 0.2618926465511322,\n"," 0.3479465842247009,\n"," 0.28579166531562805,\n"," 0.23821841180324554,\n"," 0.1841343492269516,\n"," 0.20964761078357697,\n"," 0.2727721631526947,\n"," 0.4750070869922638,\n"," 0.21271206438541412,\n"," 0.2220054715871811,\n"," 0.41622138023376465,\n"," 0.17229802906513214,\n"," 0.30132636427879333,\n"," 0.3531457781791687,\n"," 0.15765084326267242,\n"," 0.2536928951740265,\n"," 0.31439438462257385,\n"," 0.3236774206161499,\n"," 0.2566415071487427,\n"," 0.24106955528259277,\n"," 0.39113542437553406,\n"," 0.21538026630878448,\n"," 0.23260703682899475,\n"," 0.20362111926078796,\n"," 0.2301909178495407,\n"," 0.2336024045944214,\n"," 0.2976285517215729,\n"," 0.291116327047348,\n"," 0.2582066059112549,\n"," 0.32300207018852234,\n"," 0.295232892036438,\n"," 0.20094522833824158,\n"," 0.29007646441459656,\n"," 0.24525631964206696,\n"," 0.2989102303981781,\n"," 0.30605432391166687,\n"," 0.2510599195957184,\n"," 0.26102426648139954,\n"," 0.22201862931251526,\n"," 0.31842535734176636,\n"," 0.15954691171646118,\n"," 0.2510596513748169,\n"," 0.2888185679912567,\n"," 0.3699391484260559,\n"," 0.3116377592086792,\n"," 0.32405886054039,\n"," 0.2845504879951477,\n"," 0.2492489516735077,\n"," 0.2067214399576187,\n"," 0.19312907755374908,\n"," 0.24871686100959778,\n"," 0.1783069372177124,\n"," 0.2876724302768707,\n"," 0.3365108370780945,\n"," 0.2824100852012634,\n"," 0.3530765175819397,\n"," 0.3135053217411041,\n"," 0.22251473367214203,\n"," 0.2999792695045471,\n"," 0.22174307703971863,\n"," 0.2424972951412201,\n"," 0.1558735966682434,\n"," 0.18064795434474945,\n"," 0.2954210937023163,\n"," 0.2707597315311432,\n"," 0.31178200244903564,\n"," 0.18751667439937592,\n"," 0.29645177721977234,\n"," ...]"]},"metadata":{},"execution_count":19}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Resnet18.ipynb","provenance":[{"file_id":"1O5fp-hTCAAoyZqHDtPiYrG-WMJtbE8Wx","timestamp":1654753385153},{"file_id":"1Nx1CIZQUoAokxVfltbAeW93agBTpHc4S","timestamp":1654282187702},{"file_id":"1GYkqOoIaVwi5e1ReTmZ3WgI_5J2fhheb","timestamp":1653418929669}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"6ed42754d2794270bac0369bc7ace867":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a34dbaa3e70d47f4bdc3303537b039d1","IPY_MODEL_24f17e2095094d40b89f4a84548696f0","IPY_MODEL_ee392e0ccd7a4873bc28ca25a20e4679"],"layout":"IPY_MODEL_a4d8c7c44380491b94afffbfa2d37f0e"}},"a34dbaa3e70d47f4bdc3303537b039d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc058130885a4899892655db5cfb3d42","placeholder":"​","style":"IPY_MODEL_b3138245654c468ea69ac8d86ffa8852","value":"100%"}},"24f17e2095094d40b89f4a84548696f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1344ee98431e45e2b58c45a2518b1c18","max":46830571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01210a8d999c41f7a0e869aa39e73164","value":46830571}},"ee392e0ccd7a4873bc28ca25a20e4679":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2691608d6aa44946bdf36dae76388af4","placeholder":"​","style":"IPY_MODEL_b4bb3b156c39496e8dc949e4007be440","value":" 44.7M/44.7M [00:00&lt;00:00, 64.8MB/s]"}},"a4d8c7c44380491b94afffbfa2d37f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc058130885a4899892655db5cfb3d42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3138245654c468ea69ac8d86ffa8852":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1344ee98431e45e2b58c45a2518b1c18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01210a8d999c41f7a0e869aa39e73164":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2691608d6aa44946bdf36dae76388af4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4bb3b156c39496e8dc949e4007be440":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}